{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset,DataLoader \n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam,SGD,RMSprop\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "from torch.nn.init import xavier_uniform_, kaiming_normal_\n",
    "import time\n",
    "import gc\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "# sns.set(style='white')\n",
    "# style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001 # learning rate\n",
    "batch_size = 500\n",
    "weight_decay = 1e-5\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "dropout = 0.4 # replaced by bn layers\n",
    "cuda_able = True\n",
    "length_sequence = 90 # \n",
    "hidden_size = 256  # 128 -> 256\n",
    "\n",
    "bidirectional = False\n",
    "use_pe = False\n",
    "vocab_size1 = 3412772 + 1 #  creative_id\n",
    "embed_dim1 = 100\n",
    "\n",
    "vocab_size2 = 3027360 + 1 # ad_id \n",
    "embed_dim2 = 100\n",
    "\n",
    "vocab_size3 = 57870 + 1 # advertiser_id\n",
    "embed_dim3 = 100\n",
    "\n",
    "vocab_size4 = 39057 + 1 # product_id\n",
    "embed_dim4 = 100\n",
    "\n",
    "vocab_size5 = 332 + 1 # in_id\n",
    "embed_dim5 = 100\n",
    "# seed = 2020\n",
    "# torch.manual_seed(seed)\n",
    "use_cuda = torch.cuda.is_available() and cuda_able\n",
    "print(use_cuda)\n",
    "\n",
    "early_stopping_patience = 10\n",
    "save_path = 'bilstm_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('train_preliminary/user.csv')\n",
    "y_gender = labels['gender']\n",
    "y_age = labels['age']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le1 = LabelEncoder() #对性别编码\n",
    "le1 = le1.fit(y_gender)\n",
    "y_gender_labels = le1.transform(y_gender)\n",
    "le2 = LabelEncoder() #对年龄编码\n",
    "le2 = le2.fit(y_age)\n",
    "y_age_labels = le2.transform(y_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>creative_id_nunique</th>\n",
       "      <th>click_times_max</th>\n",
       "      <th>click_times_min</th>\n",
       "      <th>click_times_mean</th>\n",
       "      <th>click_times_std</th>\n",
       "      <th>click_times_count</th>\n",
       "      <th>ad_id_nunique</th>\n",
       "      <th>product_id_nunique</th>\n",
       "      <th>product_category_nunique</th>\n",
       "      <th>advertiser_id_nunique</th>\n",
       "      <th>industry_nunique</th>\n",
       "      <th>time_nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.076923</td>\n",
       "      <td>0.277350</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.022222</td>\n",
       "      <td>0.149071</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.030303</td>\n",
       "      <td>0.174078</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  creative_id_nunique  click_times_max  click_times_min  \\\n",
       "0        1                   12                2                1   \n",
       "1        2                   42                2                1   \n",
       "2        3                   30                1                1   \n",
       "3        4                   29                1                1   \n",
       "4        5                   33                2                1   \n",
       "\n",
       "   click_times_mean  click_times_std  click_times_count  ad_id_nunique  \\\n",
       "0          1.076923         0.277350                 13             12   \n",
       "1          1.022222         0.149071                 45             42   \n",
       "2          1.000000         0.000000                 30             30   \n",
       "3          1.000000         0.000000                 29             29   \n",
       "4          1.030303         0.174078                 33             33   \n",
       "\n",
       "   product_id_nunique  product_category_nunique  advertiser_id_nunique  \\\n",
       "0                   6                         3                     12   \n",
       "1                  20                         3                     36   \n",
       "2                  17                         6                     28   \n",
       "3                  18                         6                     26   \n",
       "4                   7                         4                     30   \n",
       "\n",
       "   industry_nunique  time_nunique  \n",
       "0                 9            10  \n",
       "1                15            28  \n",
       "2                 8            23  \n",
       "3                10            15  \n",
       "4                18            26  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_features_df = pd.read_csv('aggregate_features_df.csv')\n",
    "aggregate_features_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta = StandardScaler()\n",
    "_ = sta.fit_transform(aggregate_features_df.iloc[:,1:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3169476 ,  0.21785329, -0.00177705,  0.30150579,  0.48453856,\n",
       "       -0.21636036, -0.32186687, -0.54664042, -0.65150519, -0.56421382,\n",
       "       -0.56598012, -0.91885536])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = _[:900000,:]\n",
    "test_df = _[900000:,:]\n",
    "train_df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sequences():\n",
    "    with open('creative_id_sequence.pkl','rb') as f: # read creative id\n",
    "        X_cid_total = pickle.load(f)\n",
    "    with open('ad_id_sequence.pkl','rb') as f: # ad\n",
    "        X_aid_total = pickle.load(f)\n",
    "    with open('advertiser_id_sequence.pkl','rb') as f:\n",
    "        X_adid_total= pickle.load(f)\n",
    "    with open('product_id_sequence.pkl','rb') as f:\n",
    "        X_pid_total= pickle.load(f)\n",
    "    with open('industry_sequence.pkl','rb') as f:\n",
    "        X_in_total= pickle.load(f)\n",
    "    insequence_l = [len(i) if len(i) <= length_sequence else length_sequence for i in X_cid_total]\n",
    "    return X_cid_total, X_aid_total, X_adid_total,  X_pid_total, X_in_total, insequence_l     ##, X_in_total,X_aid_total X_pc_total,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cid_total, X_aid_total, X_adid_total,  X_pid_total, X_in_total,insequence_l  = load_sequences() # ,X_pc_total, X_in_total X_pc_total,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3412773, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('creative_id_embedding_ini.pkl','rb') as em:\n",
    "    word_embeddings_cid = pickle.load(em)\n",
    "word_embeddings_cid = word_embeddings_cid\n",
    "word_embeddings_cid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3027361, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('ad_id_embedding_ini.pkl','rb') as em:\n",
    "    word_embeddings_aid = pickle.load(em)\n",
    "word_embeddings_aid = word_embeddings_aid\n",
    "word_embeddings_aid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57871, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('advertiser_id_embedding_ini.pkl','rb') as em:\n",
    "    word_embeddings_adid = pickle.load(em)\n",
    "word_embeddings_adid = word_embeddings_adid\n",
    "word_embeddings_adid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39058, 100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('product_id_embedding_ini.pkl','rb') as em:\n",
    "    word_embeddings_pid = pickle.load(em)\n",
    "word_embeddings_pid = word_embeddings_pid\n",
    "word_embeddings_pid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('industry_embedding_ini.pkl','rb') as em:\n",
    "    word_embeddings_in = pickle.load(em)\n",
    "word_embeddings_in = word_embeddings_in\n",
    "word_embeddings_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "\n",
    "X_cid_total =  pad_sequences(X_cid_total,length_sequence,padding='pre',truncating='pre')\n",
    "X_aid_total =  pad_sequences(X_aid_total,length_sequence,padding='pre',truncating='pre')\n",
    "X_adid_total = pad_sequences(X_adid_total,length_sequence,padding='pre',truncating='pre')\n",
    "X_pid_total =  pad_sequences(X_pid_total,length_sequence,padding='pre',truncating='pre')\n",
    "X_in_total =   pad_sequences(X_in_total,length_sequence,padding='pre',truncating='pre')\n",
    "\n",
    "# training validate data\n",
    "X_cid = X_cid_total[:900000]\n",
    "X_aid = X_aid_total[:900000]\n",
    "X_adid = X_adid_total[:900000]\n",
    "X_pid = X_pid_total[:900000]\n",
    "X_in = X_in_total[:900000]\n",
    "\n",
    "train_sequence_length = insequence_l[:900000]\n",
    "\n",
    "# preditcion data\n",
    "for_test_cid = X_cid_total[900000:]\n",
    "for_test_aid = X_aid_total[900000:]\n",
    "for_test_adid = X_adid_total[900000:]\n",
    "for_test_pid = X_pid_total[900000:]\n",
    "for_test_in = X_in_total[900000:]\n",
    "test_sequence_length = insequence_l[900000:]\n",
    "del X_cid_total, X_aid_total, X_adid_total, X_pid_total, X_in_total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cid = torch.LongTensor(X_cid)\n",
    "X_aid = torch.LongTensor(X_aid)\n",
    "X_adid = torch.LongTensor(X_adid)\n",
    "X_pid = torch.LongTensor(X_pid)\n",
    "X_in = torch.LongTensor(X_in)\n",
    "y_gender_labels = torch.LongTensor(y_gender_labels)\n",
    "y_age_labels = torch.LongTensor(y_age_labels)\n",
    "count_feature = torch.FloatTensor(train_df)\n",
    "\n",
    "for_test_cid = torch.LongTensor(for_test_cid)\n",
    "for_test_aid = torch.LongTensor(for_test_aid)\n",
    "for_test_adid = torch.LongTensor(for_test_adid)\n",
    "for_test_pid = torch.LongTensor(for_test_pid)\n",
    "for_test_in = torch.LongTensor(for_test_in)\n",
    "for_test_count_feature = torch.FloatTensor(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('click_times_corpus.pkl','rb') as f:\n",
    "#     click_time_mask = pickle.load(f)\n",
    "# click_time_mask = pad_sequences(click_time_mask, length_sequence, padding='pre',truncating='pre')\n",
    "\n",
    "# train_ctm = click_time_mask[:900000]  # for training\n",
    "# predict_ctm = click_time_mask[900000:]# for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(i,batch_size, X_cid, X_aid, X_adid, X_pid,X_in, count_feature, y_gender_labels, y_age_labels):\n",
    "    c_batch = X_cid[i * batch_size: (i + 1) * batch_size]\n",
    "    a_batch = X_aid[i * batch_size: (i + 1) * batch_size]\n",
    "    ad_batch = X_adid[i * batch_size: (i + 1) * batch_size]\n",
    "    p_batch = X_pid[i * batch_size: (i + 1) * batch_size]\n",
    "    in_batch = X_in[i * batch_size: (i + 1) * batch_size]\n",
    "    count_batch = count_feature[i * batch_size: (i + 1) * batch_size]\n",
    "    y_gender_batch = y_gender_labels[i * batch_size: (i + 1) * batch_size]\n",
    "    y_age_batch = y_age_labels[i * batch_size: (i + 1) * batch_size] \n",
    "#     s_length = train_sequence_length[i * batch_size: (i + 1) * batch_size]\n",
    "\n",
    "    \n",
    "    return (c_batch,a_batch, ad_batch, p_batch, in_batch, count_batch ,y_gender_batch,y_age_batch)  # ,a_batch in_batch,pc_batch, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(1)\n",
    "# sns.countplot(y_gender_labels)\n",
    "# plt.figure(2)\n",
    "# sns.countplot(y_age_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,\n",
    "                 gender_output_size=2, \n",
    "                 age_output_size=10,\n",
    "                 count_input_size = 12,\n",
    "                 hidden_size=32, \n",
    "                 sequence_length = 90,\n",
    "                 vocab_size1=100, \n",
    "                 vocab_size2=100, \n",
    "                 vocab_size3=100, \n",
    "                 vocab_size4=100, \n",
    "                 vocab_size5=100,\n",
    "                 embed_dim = 100,\n",
    "                 bidirectional = True, use_pe = True,\n",
    "                 dropout = 0.1, \n",
    "                 pre_trained=True, \n",
    "                 embeddings_weight_cid=None,\n",
    "                 embeddings_weight_aid = None,\n",
    "                 embeddings_weight_adid = None,\n",
    "                 embeddings_weight_pid = None, \n",
    "                 embeddings_weight_in = None\n",
    "                ):\n",
    "        super(Model, self).__init__()\n",
    "       \n",
    "        self.gender_output_size = gender_output_size\n",
    "        self.age_output_size = age_output_size\n",
    "\n",
    "        self.count_input_size = count_input_size\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.vocab_size1 = vocab_size1\n",
    "        self.vocab_size2 = vocab_size2\n",
    "        self.vocab_size3 = vocab_size3\n",
    "        self.vocab_size4 = vocab_size4\n",
    "        self.vocab_size5 = vocab_size5\n",
    "        \n",
    "        self.bidirectional = bidirectional\n",
    "        self.use_pe = use_pe\n",
    "        self.dropout = dropout\n",
    "        self.pre_trained = pre_trained\n",
    "        self._init_weights()\n",
    "        \n",
    "        if self.pre_trained:\n",
    "            self.cid_embedding = nn.Embedding(self.vocab_size1, self.embed_dim, padding_idx=0).to(device)\n",
    "            self.cid_embedding.weight.data = torch.FloatTensor(embeddings_weight_cid).to(device)\n",
    "            self.cid_embedding.weight.requires_grad = False\n",
    "            \n",
    "            self.aid_embedding = nn.Embedding(self.vocab_size2, self.embed_dim, padding_idx=0).to(device)\n",
    "            self.aid_embedding.weight.data = torch.FloatTensor(embeddings_weight_aid).to(device)\n",
    "            self.aid_embedding.weight.requires_grad = False\n",
    "            \n",
    "            self.adid_embedding = nn.Embedding(self.vocab_size3, self.embed_dim, padding_idx=0).to(device)\n",
    "            self.adid_embedding.weight.data = torch.FloatTensor(embeddings_weight_adid).to(device)\n",
    "            self.adid_embedding.weight.requires_grad = False\n",
    "            \n",
    "            self.pid_embedding = nn.Embedding(self.vocab_size4, self.embed_dim, padding_idx=0).to(device)\n",
    "            self.pid_embedding.weight.data = torch.FloatTensor(embeddings_weight_pid).to(device)\n",
    "            self.pid_embedding.weight.requires_grad = False\n",
    "            \n",
    "            self.in_embedding = nn.Embedding(self.vocab_size5, self.embed_dim, padding_idx=0).to(device)\n",
    "            self.in_embedding.weight.data = torch.FloatTensor(embeddings_weight_in).to(device)\n",
    "            self.in_embedding.weight.requires_grad = False\n",
    "        \n",
    "        self.layer_size = 1\n",
    "        self.kernel_size = 2\n",
    "        \n",
    "        self.out_channels = 128\n",
    "        \n",
    "        encoder_layer1 = nn.TransformerEncoderLayer(d_model = self.embed_dim, nhead = 4).to(device)\n",
    "        self.encoder1 = nn.TransformerEncoder(encoder_layer1, 1).to(device)\n",
    "        \n",
    "        encoder_layer2 = nn.TransformerEncoderLayer(d_model = self.embed_dim, nhead = 4).to(device)\n",
    "        self.encoder2 = nn.TransformerEncoder(encoder_layer2, 1).to(device)\n",
    "        \n",
    "        encoder_layer3 = nn.TransformerEncoderLayer(d_model = self.embed_dim, nhead = 4).to(device)\n",
    "        self.encoder3 = nn.TransformerEncoder(encoder_layer3, 1).to(device)\n",
    "        \n",
    "        encoder_layer4 = nn.TransformerEncoderLayer(d_model = self.embed_dim, nhead = 4).to(device)\n",
    "        self.encoder4 = nn.TransformerEncoder(encoder_layer4, 1).to(device)\n",
    "        \n",
    "        encoder_layer5 = nn.TransformerEncoderLayer(d_model = self.embed_dim, nhead = 4).to(device)\n",
    "        self.encoder5 = nn.TransformerEncoder(encoder_layer5, 1).to(device)\n",
    "        \n",
    "        self.lstm1 = nn.GRU(self.embed_dim, self.hidden_size, self.layer_size,\n",
    "                            bidirectional=self.bidirectional,batch_first = True,bias=True).to(device)\n",
    "\n",
    "        self.lstm2 = nn.GRU(self.embed_dim, self.hidden_size, self.layer_size,\n",
    "                            bidirectional=self.bidirectional,batch_first = True).to(device)\n",
    "        \n",
    "        self.lstm3 = nn.GRU(self.embed_dim, self.hidden_size, self.layer_size,\n",
    "                            bidirectional=self.bidirectional,batch_first = True,bias=True).to(device)\n",
    "        \n",
    "        self.lstm4 = nn.GRU(self.embed_dim, self.hidden_size, self.layer_size,\n",
    "                            bidirectional=self.bidirectional,batch_first = True,bias=True).to(device) \n",
    "        \n",
    "        self.lstm5 = nn.GRU(self.embed_dim, self.hidden_size, self.layer_size,\n",
    "                    bidirectional=self.bidirectional,batch_first = True,bias=True).to(device) \n",
    "        \n",
    "        self.pool1 = nn.MaxPool1d(self.sequence_length).to(device)\n",
    "        self.pool2 = nn.MaxPool1d(self.sequence_length).to(device)\n",
    "        self.pool3 = nn.MaxPool1d(self.sequence_length).to(device)\n",
    "        self.pool4 = nn.MaxPool1d(self.sequence_length).to(device)\n",
    "        self.pool5 = nn.MaxPool1d(self.sequence_length).to(device)\n",
    "\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            self.layer_size = self.layer_size * 2\n",
    "        \n",
    "        self.shared_layer = nn.Sequential( \n",
    "                                nn.Linear(self.hidden_size * 5 + 512, 1024),\n",
    "                                nn.BatchNorm1d(1024),\n",
    "                                nn.ReLU(inplace = True),\n",
    "                                nn.Dropout(0.5),\n",
    "                                \n",
    "                                nn.Linear(1024,512), \n",
    "                                nn.BatchNorm1d(512),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Dropout(0.5)).to(device)\n",
    "        \n",
    "        self.mlp = nn.Sequential( \n",
    "                                nn.Linear(self.count_input_size, 1024),\n",
    "                                nn.BatchNorm1d(1024),\n",
    "                                nn.ReLU(inplace = True),\n",
    "                                nn.Dropout(0.5),\n",
    "                                \n",
    "                                nn.Linear(1024,512), \n",
    "                                nn.BatchNorm1d(512),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Dropout(0.5)).to(device)\n",
    "\n",
    "        \n",
    "        self.gender = nn.Linear(512, self.gender_output_size).to(device)\n",
    "        \n",
    "        self.age =  nn.Linear(512,self.age_output_size).to(device)\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                kaiming_normal_(p, mode='fan_out', nonlinearity='relu')\n",
    "   \n",
    "    def get_padding_mask(self, batch_size, seq_len, inp_len):\n",
    "        padding_mask = np.ones((batch_size, seq_len))\n",
    "        for index, l in enumerate(inp_len):\n",
    "            padding_mask[index,:l] = 0\n",
    "        return torch.from_numpy(padding_mask).bool().to(device)\n",
    "    \n",
    "    def forward(self, x_cid, x_aid, x_adid,x_pid, x_in, x_count_feature):  #  x_pc, x_in,  x_aid\n",
    "        \n",
    "        x_c_f = self.mlp(x_count_feature)\n",
    "        \n",
    "        \n",
    "#         batch_size, seq_len = x_cid.shape\n",
    "#         inp_padding_mask = self.get_padding_mask(batch_size, seq_len, s_length)\n",
    "        cid = self.cid_embedding(x_cid).permute(1,0,2)\n",
    "        aid = self.aid_embedding(x_aid).permute(1,0,2)\n",
    "        adid = self.adid_embedding(x_adid).permute(1,0,2)  # [sequnce_length, batch_size, embed_size]\n",
    "        pid = self.pid_embedding(x_pid).permute(1,0,2)\n",
    "        inid = self.in_embedding(x_in).permute(1,0,2)\n",
    "        \n",
    "        cout = self.encoder1(cid)  #  [sequnce_length, batch_size, embed_size]\n",
    "        aout = self.encoder2(aid)\n",
    "        adout = self.encoder3(adid)   # , src_key_padding_mask = inp_padding_mask\n",
    "        pout = self.encoder4(pid)\n",
    "        inout = self.encoder5(inid)\n",
    "        \n",
    "        cout = cout.permute(1,0,2) #  [batch_size,sequence_length,embed_size]\n",
    "        aout = aout.permute(1,0,2)\n",
    "        adout = adout.permute(1,0,2)\n",
    "        pout = pout.permute(1,0,2)\n",
    "        inout = inout.permute(1,0,2)\n",
    "        \n",
    "        cout = self.lstm1(cout)[0].permute(0,2,1)  #  batch_size,embed_size , equence_length,\n",
    "        aout = self.lstm2(aout)[0].permute(0,2,1)\n",
    "        adout = self.lstm3(adout)[0].permute(0,2,1)\n",
    "        pout = self.lstm4(pout)[0].permute(0,2,1)\n",
    "        inout = self.lstm5(inout)[0].permute(0,2,1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        c_conv_out =  F.dropout(F.relu(self.pool1(cout)), p = 0.5, training = self.training)\n",
    "        a_conv_out =  F.dropout(F.relu(self.pool2(aout)), p = 0.5, training = self.training)\n",
    "        ad_conv_out = F.dropout(F.relu(self.pool3(adout)),p = 0.5, training = self.training)\n",
    "        p_conv_out =  F.dropout(F.relu(self.pool4(pout)), p = 0.5, training = self.training)\n",
    "        i_conv_out =  F.dropout(F.relu(self.pool5(inout)), p = 0.5, training = self.training)\n",
    "#         conv_out = torch.cat((c_conv_out, a_conv_out,  ad_conv_out, pc_conv_out, in_conv_out),dim=1) # a_conv_out, \n",
    "#         out = conv_out.view(conv_out.shape[0] ,-1)\n",
    "        out =  torch.cat((c_conv_out ,   a_conv_out , i_conv_out , ad_conv_out,p_conv_out ), dim = 1)# \n",
    "#         out = c_conv_out + ad_conv_out + p_conv_out\n",
    "        out = out.squeeze()\n",
    "        \n",
    "        out = torch.cat((out, x_c_f), dim = 1)\n",
    "        out = self.shared_layer(out)\n",
    "        return self.gender(out),self.age(out)\n",
    "\n",
    "    \n",
    "model = Model(\n",
    "            gender_output_size=2,\n",
    "            age_output_size = 10,\n",
    "            hidden_size=hidden_size,\n",
    "            sequence_length = length_sequence,\n",
    "            count_input_size = 12,\n",
    "            embed_dim =100,\n",
    "            \n",
    "            vocab_size1=vocab_size1,\n",
    "            vocab_size2=vocab_size2,\n",
    "            vocab_size3=vocab_size3, \n",
    "            vocab_size4=vocab_size4,\n",
    "            vocab_size5=vocab_size5,\n",
    "            \n",
    "            bidirectional=bidirectional,\n",
    "            use_pe = use_pe,\n",
    "            dropout=dropout,\n",
    "            pre_trained=True,\n",
    "            embeddings_weight_cid= word_embeddings_cid,\n",
    "            embeddings_weight_aid= word_embeddings_aid,\n",
    "            embeddings_weight_adid = word_embeddings_adid,\n",
    "            embeddings_weight_pid = word_embeddings_pid, \n",
    "            embeddings_weight_in = word_embeddings_in, \n",
    "                    )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # optimizer = RMSprop(model.parameters(),lr = lr, weight_decay = weight_decay)\n",
    "encoder1_params = list(map(id,model.encoder1.parameters()))\n",
    "encoder2_params = list(map(id,model.encoder2.parameters()))\n",
    "encoder3_params = list(map(id,model.encoder3.parameters()))\n",
    "encoder4_params = list(map(id,model.encoder4.parameters()))\n",
    "encoder5_params = list(map(id,model.encoder5.parameters()))\n",
    "base_params = filter(lambda p: id(p) not in encoder1_params + encoder2_params + encoder3_params + encoder4_params + encoder5_params, model.parameters())\n",
    "optimizer = Adam([\n",
    "    {'params':base_params},\n",
    "    {'params':model.encoder1.parameters(), 'lr': lr / 2.0},\n",
    "    {'params':model.encoder2.parameters(), 'lr': lr / 2.0},\n",
    "    {'params':model.encoder3.parameters(), 'lr': lr / 2.0},\n",
    "    {'params':model.encoder4.parameters(), 'lr': lr / 2.0},\n",
    "    {'params':model.encoder5.parameters(), 'lr': lr / 2.0},\n",
    "], lr = lr)\n",
    "# optimizer = Adam(model.parameters(), lr = lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=0, threshold=1e-5, threshold_mode='abs')\n",
    "    \n",
    "lossfunc1 = torch.nn.CrossEntropyLoss()\n",
    "lossfunc2 = torch.nn.CrossEntropyLoss()\n",
    "# lossfunc2 = FocalLoss(class_num = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_res_gender = []\n",
    "# test_res_age = []\n",
    "\n",
    "# def get_k_fold_data(k, i, X_cid, X_aid, X_adid, X_pid, X_in, Count_features, y_gender_labels, y_age_labels):\n",
    "#     assert k > 1\n",
    "#     fold_size = 900000 // k  # k = 5 3 input\n",
    "    \n",
    "#     X_cid_train, X_adid_train, y_gender_train, y_age_train = None, None, None, None\n",
    "#     for j in range(k):\n",
    "#         idx = slice(j * fold_size, (j+1) * fold_size)\n",
    "#         x_cid_part, x_aid_part, x_adid_part, x_pid_part,x_in_part, count_features_part, y_gender_part, y_age_part = \\\n",
    "#         X_cid[idx,:],X_aid[idx,:], X_adid[idx,:], X_pid[idx,:],X_in[idx,:] ,Count_features[idx,:], y_gender_labels[idx],y_age_labels[idx]\n",
    "#         if j == i :\n",
    "#             X_cid_val,X_aid_val, X_adid_val, X_pid_val, X_in_val, Count_features_val, y_gender_val, y_age_val = \\\n",
    "#             x_cid_part, x_aid_part, x_adid_part, x_pid_part , x_in_part,count_features_part,  y_gender_part, y_age_part\n",
    "#         elif X_cid_train is None:\n",
    "#             X_cid_train, X_aid_train, X_adid_train, X_pid_train, X_in_train, Count_features_train, y_gender_train, y_age_train = \\\n",
    "#             x_cid_part, x_aid_part, x_adid_part, x_pid_part, x_in_part, count_features_part, y_gender_part, y_age_part\n",
    "#         else:\n",
    "#             X_cid_train = torch.cat((X_cid_train,x_cid_part),dim = 0)\n",
    "#             X_aid_train = torch.cat((X_aid_train,x_aid_part),dim = 0)\n",
    "#             X_adid_train = torch.cat((X_adid_train,x_adid_part),dim = 0)\n",
    "#             X_pid_train = torch.cat((X_pid_train,x_pid_part),dim = 0)\n",
    "#             X_in_train = torch.cat((X_in_train, x_in_part),dim = 0)\n",
    "#             Count_features_train = torch.cat((Count_features_train,count_features_part),dim = 0)\n",
    "#             y_gender_train = torch.cat((y_gender_train, y_gender_part),dim = 0)\n",
    "#             y_age_train = torch.cat((y_age_train,y_age_part),dim = 0)\n",
    "#     return X_cid_train, X_aid_train, X_adid_train, X_pid_train, X_in_train, Count_features_train, y_gender_train,y_age_train,\\\n",
    "#            X_cid_val, X_aid_val, X_adid_val,X_pid_val, X_in_val, Count_features_val, y_gender_val,y_age_val\n",
    "\n",
    "\n",
    "# def k_fold(k, X_cid, X_aid, X_adid, X_pid, X_in, Count_features, y_gender_labels, y_age_labels):\n",
    "    \n",
    "#     train_loss_gender_sum = 0.0\n",
    "#     valid_loss_gender_sum = 0.0\n",
    "\n",
    "#     train_loss_age_sum = 0.0\n",
    "#     valid_loss_age_sum = 0.0\n",
    "    \n",
    "    \n",
    "    \n",
    "#     train_acc_gender_sum = 0.0\n",
    "#     valid_acc_gender_sum = 0.0\n",
    "\n",
    "#     train_acc_age_sum = 0.0\n",
    "#     valid_acc_age_sum = 0.0\n",
    "#     val_res_gender = None\n",
    "#     val_res_age = None\n",
    "\n",
    "#     for i in range(k):\n",
    "#         data = get_k_fold_data(k, i, X_cid, X_aid, X_adid, X_pid, X_in, count_feature, y_gender_labels, y_age_labels)\n",
    "          \n",
    "    \n",
    "#         model = Model(\n",
    "#                     gender_output_size=2,\n",
    "#                     age_output_size = 10,\n",
    "#                     hidden_size=hidden_size,\n",
    "#                     sequence_length = length_sequence,\n",
    "#                     count_input_size = 12,\n",
    "#                     embed_dim =100,\n",
    "\n",
    "#                     vocab_size1=vocab_size1,\n",
    "#                     vocab_size2=vocab_size2,\n",
    "#                     vocab_size3=vocab_size3,\n",
    "#                     vocab_size4=vocab_size4,\n",
    "#                     vocab_size5=vocab_size5,\n",
    "\n",
    "#                     bidirectional=bidirectional,\n",
    "#                     use_pe = use_pe,\n",
    "#                     dropout=dropout,\n",
    "#                     pre_trained=True,\n",
    "#                     embeddings_weight_cid= word_embeddings_cid,\n",
    "#                     embeddings_weight_aid= word_embeddings_aid,\n",
    "#                     embeddings_weight_adid = word_embeddings_adid,\n",
    "#                     embeddings_weight_pid = word_embeddings_pid, \n",
    "#                     embeddings_weight_in = word_embeddings_in, \n",
    "#                             )\n",
    "            \n",
    "\n",
    "#         model, val_gender_fold, val_age_fold , train_ls_gender, train_ls_age, valid_ls_gender, valid_ls_age  = train(i, model, *data)\n",
    "\n",
    "#         if val_res_gender is None:\n",
    "#             val_res_gender = val_gender_fold\n",
    "#             val_res_age = val_age_fold\n",
    "#         else:\n",
    "#             val_res_gender = torch.cat((val_res_gender,val_gender_fold),0)\n",
    "#             val_res_age = torch.cat((val_res_age,val_age_fold),0)\n",
    "\n",
    "\n",
    "#         print('*'*25,'第',i+1,'折','*'*25)\n",
    "#         print('train_gender_loss:%.4f'%train_ls_gender[-1][0],'train_gender_acc:%.4f\\n'%train_ls_gender[-1][1],\\\n",
    "#               'train_age_loss:%.4f'%train_ls_age[-1][0],'train_age_acc:%.4f\\n'%train_ls_age[-1][1],\\\n",
    "#               'valid_gender_loss:%.4f'%valid_ls_gender[-1][0],'valid_gender_acc:%.4f\\n'%valid_ls_gender[-1][1],\\\n",
    "#               'valid_age_loss:%.4f'%valid_ls_age[-1][0],'valid_age_acc:%.4f\\n'%valid_ls_age[-1][1]\n",
    "#              )\n",
    "#         train_loss_gender_sum += train_ls_gender[-1][0]\n",
    "#         train_acc_gender_sum += train_ls_gender[-1][1]\n",
    "\n",
    "#         train_loss_age_sum += train_ls_age[-1][0]\n",
    "#         train_acc_age_sum += train_ls_age[-1][1]\n",
    "\n",
    "#         valid_loss_gender_sum += valid_ls_gender[-1][0]\n",
    "#         valid_acc_gender_sum += valid_ls_gender[-1][1]\n",
    "#         valid_loss_age_sum += valid_ls_age[-1][0]\n",
    "#         valid_acc_age_sum +=valid_ls_age[-1][1]\n",
    "#         # record test output for stacking\n",
    "#         _ = predict(model)\n",
    "#         test_res_gender.append(_[0]) # average predict result\n",
    "#         test_res_age.append(_[1])\n",
    "\n",
    "#         del model \n",
    "#         _ = gc.collect()\n",
    "#         torch.cuda.empty_cache()\n",
    "#         time.sleep(5)\n",
    "#     print('#'*10,'最终k折交叉验证结果','#'*10) \n",
    "#     print('train_loss_gender_sum:%.4f'%(train_loss_gender_sum/k),'train_acc_gender_sum:%.4f'%(train_acc_gender_sum/k),\\\n",
    "#           'train_loss_age_sum:%.4f'%( train_loss_age_sum/k),   'train_loss_age_sum:%.4f\\n'%(train_acc_age_sum/k),\\\n",
    "#           'valid_loss_gender_sum:%.4f'%(valid_loss_gender_sum/k),'valid_acc_gender_sum:%.4f'%(valid_acc_gender_sum /k),\\\n",
    "#           'valid_loss_age_sum:%.4f'%(valid_loss_age_sum/k),'valid_acc_age_sum:%.4f'%(valid_acc_age_sum/k))\n",
    "#     return val_res_gender, val_res_age\n",
    "                                    \n",
    "\n",
    "# def train(fold , model,X_cid_train, X_aid_train, X_adid_train, X_pid_train, X_in_train, Count_features_train, y_gender_train,y_age_train,\\\n",
    "#           X_cid_val, X_aid_val, X_adid_val,X_pid_val,X_in_val, Count_features_val, y_gender_val,y_age_val):\n",
    "    \n",
    "#     train_ls_gender, train_ls_age = [], []\n",
    "#     valid_ls_gender, valid_ls_age = [], []\n",
    "    \n",
    "#     n = X_cid_train.shape[0]\n",
    "#     m = X_cid_val.shape[0]\n",
    "    \n",
    "#     encoder1_params = list(map(id,model.encoder1.parameters()))\n",
    "#     encoder2_params = list(map(id,model.encoder2.parameters()))\n",
    "#     encoder3_params = list(map(id,model.encoder3.parameters()))\n",
    "#     encoder4_params = list(map(id,model.encoder4.parameters()))\n",
    "#     encoder5_params = list(map(id,model.encoder5.parameters()))\n",
    "#     base_params = filter(lambda p: id(p) not in encoder1_params + encoder2_params + encoder3_params + encoder4_params + encoder5_params, model.parameters())\n",
    "#     optimizer = Adam([\n",
    "#         {'params':base_params},\n",
    "#         {'params':model.encoder1.parameters(), 'lr': lr / 2.0},\n",
    "#         {'params':model.encoder2.parameters(), 'lr': lr / 2.0},\n",
    "#         {'params':model.encoder3.parameters(), 'lr': lr / 2.0},\n",
    "#         {'params':model.encoder4.parameters(), 'lr': lr / 2.0},\n",
    "#         {'params':model.encoder5.parameters(), 'lr': lr / 2.0},\n",
    "#     ], lr = lr)\n",
    "\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=0, threshold=1e-5, threshold_mode='abs')\n",
    "        \n",
    "#     best_model = None\n",
    "#     max_acc_sum = 0.0\n",
    "#     val_gender_preds, val_age_preds = None, None\n",
    "#     # training\n",
    "    \n",
    "#     for epoch in range(epochs):\n",
    "#         print('epoch {}'.format(epoch+1))\n",
    "#         model.train()\n",
    "#         try:\n",
    "#             with tqdm(range(n // batch_size)) as t:\n",
    "#                 train_loss_gender = []\n",
    "#                 train_loss_age = []\n",
    "#                 train_acc_gender = 0.\n",
    "#                 train_acc_age = 0.\n",
    "#                 for i in t:\n",
    "#                     c_batch,a_batch, ad_batch, p_batch, in_batch, count_batch ,y_gender_batch,y_age_batch = \\\n",
    "#                     get_batch(i, batch_size,X_cid_train, X_aid_train, X_adid_train, X_pid_train, X_in_train, Count_features_train, y_gender_train,y_age_train)\n",
    "#                     optimizer.zero_grad()\n",
    "#                     gender,age = model(c_batch.to(device),\n",
    "#                                        a_batch.to(device), \n",
    "#                                        ad_batch.to(device), \n",
    "#                                        p_batch.to(device),\n",
    "#                                        in_batch.to(device),\n",
    "#                                        count_batch.to(device)\n",
    "#                     )\n",
    "                    \n",
    "                    \n",
    "#                     loss1 = lossfunc1(gender,y_gender_batch.to(device))     \n",
    "#                     loss2 = lossfunc2(age,y_age_batch.to(device))\n",
    "\n",
    "#                     t_loss = 0.5 * loss1  + 0.5 * loss2\n",
    "                    \n",
    "#                     train_loss_gender.append(float(loss1)) \n",
    "#                     train_loss_age.append(float(loss2))\n",
    "#                     del loss1,loss2,c_batch, ad_batch\n",
    "\n",
    "#                     pred_gender =  torch.max(gender,1)[1]\n",
    "#                     pred_age =  torch.max(age,1)[1]\n",
    "\n",
    "#                     train_correct_gender = (pred_gender.cpu() == y_gender_batch).sum()\n",
    "#                     train_acc_gender += train_correct_gender.item()\n",
    "\n",
    "#                     train_correct_age = (pred_age.cpu()== y_age_batch).sum()\n",
    "#                     train_acc_age += train_correct_age.item()\n",
    "        \n",
    "                  \n",
    "#                     t_loss.backward()\n",
    "#                     nn.utils.clip_grad_norm_(model.parameters(), max_norm=100)\n",
    "#                     optimizer.step()\n",
    "# #                     scheduler.step()\n",
    "                    \n",
    "# #                     break\n",
    "#                 print('Train_loss_gender:{:0.4f},acc_gender = {:0.4f}, Train_loss_age:{:0.4f},acc_age = {:0.4f}'.format(np.mean(train_loss_gender),train_acc_gender/n,np.mean(train_loss_age),train_acc_age/n))\n",
    "#                 train_ls_gender.append((np.mean(train_loss_gender),train_acc_gender/ n) ) # plot train\n",
    "#                 train_ls_age.append((np.mean(train_loss_age), train_acc_age/ n))\n",
    "#         except KeyboardInterrupt:\n",
    "#             t.close()\n",
    "#             break\n",
    "#         t.close()\n",
    "#         # validation\n",
    "#         torch.cuda.empty_cache()\n",
    "#         model.eval()\n",
    "#         eval_loss_gender = []\n",
    "#         eval_loss_age = []\n",
    "#         eval_acc_gender = 0.\n",
    "#         eval_acc_age = 0.\n",
    "#         _temp1, _temp2 = None, None\n",
    "#         with torch.no_grad():\n",
    "#             for i in range(m // batch_size):\n",
    "                \n",
    "#                 c_batch,a_batch, ad_batch, p_batch, in_batch, count_batch ,y_gender_batch,y_age_batch = \\\n",
    "#                 get_batch(i, batch_size,X_cid_val, X_aid_val, X_adid_val, X_pid_val, X_in_val,Count_features_val, y_gender_val,y_age_val)\n",
    "#                 gender,age = model(c_batch.to(device),\n",
    "#                                    a_batch.to(device), \n",
    "#                                    ad_batch.to(device), \n",
    "#                                    p_batch.to(device),\n",
    "#                                    in_batch.to(device),\n",
    "#                                    count_batch.to(device)\n",
    "#                 )\n",
    "#                 if _temp1 is None:\n",
    "#                     _temp1 = gender\n",
    "#                     _temp2 = age\n",
    "#                 else:\n",
    "#                     _temp1 = torch.cat((_temp1,gender), 0 )\n",
    "#                     _temp2 = torch.cat((_temp2,age), 0 )\n",
    "                    \n",
    "#                 loss1 = lossfunc1(gender,y_gender_batch.to(device))\n",
    "#                 loss2 = lossfunc2(age,y_age_batch.to(device))\n",
    "#                 eval_loss_gender.append(loss1.item())\n",
    "#                 eval_loss_age.append(loss2.item())\n",
    "                \n",
    "#                 pred_gender = torch.max(gender,1)[1]  # out_gender \n",
    "#                 eval_correct_gender = (pred_gender.cpu() == y_gender_batch).sum()\n",
    "#                 eval_acc_gender += eval_correct_gender.item() \n",
    "                \n",
    "#                 pred_age = torch.max(age,1)[1] # age_out\n",
    "                \n",
    "#                 eval_correct_age = ( pred_age.cpu() == y_age_batch).sum()\n",
    "#                 eval_acc_age += eval_correct_age.item()\n",
    "\n",
    "#             print('Eval_loss_gender:{:0.4f},acc_gender = {:0.4f}, Eval_loss_age:{:0.4f},acc_age = {:0.4f}'.format(np.mean(eval_loss_gender),eval_acc_gender / m, np.mean(eval_loss_age),eval_acc_age / m))\n",
    "#             valid_ls_gender.append((np.mean(eval_loss_gender),eval_acc_gender/ m )) # plot train\n",
    "#             valid_ls_age.append((np.mean(eval_loss_age), eval_acc_age/ m))\n",
    "#             print('score = {:0.4f}'.format(eval_acc_gender / m  +  eval_acc_age / m))\n",
    "#             scheduler.step(eval_acc_gender / m  +  eval_acc_age / m)\n",
    "#             if eval_acc_gender / m  +  eval_acc_age / m > max_acc_sum:\n",
    "#                 max_acc_sum = eval_acc_gender / m  +  eval_acc_age / m\n",
    "#                 best_model = model\n",
    "#                 val_gender_preds, val_age_preds = _temp1, _temp2\n",
    "#     print('*'* 25, 'saving best model with max_acc_sum = ', max_acc_sum)\n",
    "#     path = 'fold_'+str(fold) + 'best'+ save_path\n",
    "#     torch.save(best_model.state_dict(),path)\n",
    "#     return best_model,val_gender_preds, val_age_preds , train_ls_gender, train_ls_age, valid_ls_gender, valid_ls_age\n",
    "    \n",
    "# def predict(model):\n",
    "#     model.eval()\n",
    "#     test_prob_gender = None\n",
    "#     test_prob_age = None\n",
    "#     print('begin predict')\n",
    "#     with torch.no_grad():\n",
    "#         for i in tqdm(range( 1000000 // batch_size)):  # 10000 for test\n",
    "\n",
    "#             c_id = torch.LongTensor(for_test_cid[i * batch_size : (i+1) * batch_size])\n",
    "#             a_id = torch.LongTensor(for_test_aid[i * batch_size : (i+1) * batch_size])\n",
    "#             ad_id = torch.LongTensor(for_test_adid[i * batch_size : (i+1) * batch_size])\n",
    "#             p_id = torch.LongTensor(for_test_pid[i * batch_size : (i+1) * batch_size])\n",
    "#             in_id = torch.LongTensor(for_test_in[i * batch_size : (i+1) * batch_size])\n",
    "#             count_feature = torch.FloatTensor(for_test_count_feature[i * batch_size : (i+1) * batch_size])\n",
    "# #             s_length = test_sequence_length[i * batch_size : (i+1) * batch_size]p_id.cuda(0), in_id.cuda(0),\n",
    "#             gender,age = model(c_id.cuda(0),a_id.cuda(0), ad_id.cuda(0),p_id.cuda(0),in_id.cuda(0),count_feature.cuda(0))\n",
    "#             if test_prob_gender is None:\n",
    "#                 test_prob_gender = gender\n",
    "#                 test_prob_age = age\n",
    "#             else:\n",
    "#                 test_prob_gender = torch.cat((test_prob_gender,gender),dim = 0)\n",
    "#                 test_prob_age = torch.cat((test_prob_age,age),dim = 0)\n",
    "#     return test_prob_gender,test_prob_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# _gender, _age = k_fold(5, X_cid, X_aid, X_adid, X_pid, X_in, count_feature, y_gender_labels, y_age_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # average predict_res\n",
    "# preds_gender =  torch.mean(torch.stack(test_res_gender,0), 0)\n",
    "# preds_age = torch.mean(torch.stack(test_res_age,0),0)\n",
    "# preds_gender.shape,preds_age.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = np.hstack((_gender.cpu().detach().numpy() , _age.cpu().detach().numpy()))\n",
    "# test_set = np.hstack((preds_gender.cpu().detach().numpy(),preds_age.cpu().detach().numpy()))\n",
    "# train_set.shape,test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_gender = np.zeros(1000000)\n",
    "# out_age = np.zeros(1000000)\n",
    "# out_gender = torch.max(preds_gender,1)[1].cpu().numpy() \n",
    "# out_age = torch.max(preds_age,1)[1].cpu().numpy()\n",
    "# plt.figure(1)\n",
    "# sns.countplot(out_gender)\n",
    "# plt.figure(2)\n",
    "# sns.countplot(out_age)\n",
    "\n",
    "# output = pd.DataFrame(columns=['user_id'])\n",
    "# # # print(len(test_preds_age))\n",
    "# output['user_id'] = list(range(3000001,4000001))\n",
    "# output['predicted_age'] = list(map(lambda x:int(x) + 1,out_age))\n",
    "# output['predicted_gender']= list(map(lambda x:int(x) + 1,out_gender))\n",
    "\n",
    "# import datetime\n",
    "# date_p = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "# output.to_csv('submit'+ date_p+ '.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1780 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1780/1780 [07:20<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss_gender:0.1852,acc_gender = 0.9343, Train_loss_age:1.4261,acc_age = 0.4123\n",
      "Eval_loss_gender:0.1687,acc_gender = 0.9415, Eval_loss_age:1.3376,acc_age = 0.4449\n",
      "score = 1.3864\n",
      "--------------------saving best model at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzp/.conda/envs/lzpven/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type Model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "  0%|          | 0/1780 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished saving\n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1780/1780 [07:19<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss_gender:0.1720,acc_gender = 0.9398, Train_loss_age:1.3448,acc_age = 0.4433\n",
      "Eval_loss_gender:0.1657,acc_gender = 0.9415, Eval_loss_age:1.3109,acc_age = 0.4571\n",
      "score = 1.3986\n",
      "--------------------saving best model at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1780 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished saving\n",
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1780/1780 [07:12<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss_gender:0.1681,acc_gender = 0.9415, Train_loss_age:1.3182,acc_age = 0.4540\n",
      "Eval_loss_gender:0.1646,acc_gender = 0.9436, Eval_loss_age:1.2913,acc_age = 0.4664\n",
      "score = 1.4100\n",
      "--------------------saving best model at epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1780 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished saving\n",
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1780/1780 [07:12<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss_gender:0.1652,acc_gender = 0.9426, Train_loss_age:1.3000,acc_age = 0.4615\n",
      "Eval_loss_gender:0.1618,acc_gender = 0.9423, Eval_loss_age:1.2768,acc_age = 0.4723\n",
      "score = 1.4146\n",
      "--------------------saving best model at epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1780 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished saving\n",
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1780/1780 [07:11<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss_gender:0.1625,acc_gender = 0.9437, Train_loss_age:1.2851,acc_age = 0.4672\n",
      "Eval_loss_gender:0.1608,acc_gender = 0.9426, Eval_loss_age:1.2730,acc_age = 0.4748\n",
      "score = 1.4174\n",
      "--------------------saving best model at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1780 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished saving\n",
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1780/1780 [07:10<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss_gender:0.1604,acc_gender = 0.9446, Train_loss_age:1.2727,acc_age = 0.4722\n",
      "Eval_loss_gender:0.1609,acc_gender = 0.9434, Eval_loss_age:1.2685,acc_age = 0.4750\n",
      "score = 1.4184\n",
      "--------------------saving best model at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1780 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished saving\n",
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1780/1780 [07:12<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss_gender:0.1579,acc_gender = 0.9455, Train_loss_age:1.2610,acc_age = 0.4763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1780 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval_loss_gender:0.1605,acc_gender = 0.9421, Eval_loss_age:1.2652,acc_age = 0.4745\n",
      "score = 1.4166\n",
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1780/1780 [07:11<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss_gender:0.1523,acc_gender = 0.9476, Train_loss_age:1.2341,acc_age = 0.4863\n",
      "Eval_loss_gender:0.1609,acc_gender = 0.9423, Eval_loss_age:1.2588,acc_age = 0.4807\n",
      "score = 1.4230\n",
      "--------------------saving best model at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1780 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished saving\n",
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1780/1780 [07:10<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss_gender:0.1494,acc_gender = 0.9490, Train_loss_age:1.2217,acc_age = 0.4913\n",
      "Eval_loss_gender:0.1618,acc_gender = 0.9423, Eval_loss_age:1.2579,acc_age = 0.4809\n",
      "score = 1.4232\n",
      "--------------------saving best model at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1780 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished saving\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1780/1780 [07:11<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss_gender:0.1475,acc_gender = 0.9496, Train_loss_age:1.2119,acc_age = 0.4950\n",
      "Eval_loss_gender:0.1625,acc_gender = 0.9429, Eval_loss_age:1.2594,acc_age = 0.4801\n",
      "score = 1.4230\n",
      "training finished\n"
     ]
    }
   ],
   "source": [
    "def train_with_early_stopping():\n",
    "#     val_loss_full = []\n",
    "    max_acc_sum = 0.\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        print('epoch {}'.format(epoch+1))\n",
    "        train_loss_full = []\n",
    "        val_loss_full = []\n",
    "        try:\n",
    "            with tqdm(range(890000 //batch_size)) as t:\n",
    "                \n",
    "                train_loss_gender = []\n",
    "                train_loss_age = []\n",
    "                train_acc_gender = 0.\n",
    "                train_acc_age = 0.\n",
    "                for i in t:\n",
    "                    c_batch,a_batch, ad_batch, p_batch, in_batch, count_batch ,y_gender_batch,y_age_batch = \\\n",
    "                    get_batch(i,batch_size, X_cid,X_aid, X_adid,X_pid,X_in, count_feature, y_gender_labels, y_age_labels)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    gender,age = model(c_batch.to(device),\n",
    "                                       a_batch.to(device), \n",
    "                                       ad_batch.to(device), \n",
    "                                       p_batch.to(device),\n",
    "                                       in_batch.to(device),\n",
    "                                       count_batch.to(device)\n",
    "                    )\n",
    "                    \n",
    "                    loss1 = lossfunc1(gender,y_gender_batch.to(device))     \n",
    "                    loss2 = lossfunc2(age,y_age_batch.to(device))\n",
    "\n",
    "                    t_loss = 0.5 * loss1  +   0.5 *  loss2\n",
    "                \n",
    "                    \n",
    "                    train_loss_gender.append(float(loss1)) \n",
    "                    train_loss_age.append(float(loss2))\n",
    "                    del loss1,loss2,c_batch, ad_batch\n",
    "\n",
    "                    pred_gender =  torch.max(gender,1)[1]\n",
    "                    pred_age =  torch.max(age,1)[1]\n",
    "\n",
    "                    train_correct_gender = (pred_gender.cpu() == y_gender_batch).sum()\n",
    "                    train_acc_gender += train_correct_gender.item()\n",
    "\n",
    "                    train_correct_age = (pred_age.cpu()== y_age_batch).sum()\n",
    "                    train_acc_age += train_correct_age.item()\n",
    "        \n",
    "                  \n",
    "                    t_loss.backward()\n",
    "                    nn.utils.clip_grad_norm_(model.parameters(), max_norm=100)\n",
    "                    optimizer.step()\n",
    "#                     scheduler.step()\n",
    "                    \n",
    "    \n",
    "    \n",
    "\n",
    "#                     break\n",
    "                print('Train_loss_gender:{:0.4f},acc_gender = {:0.4f}, Train_loss_age:{:0.4f},acc_age = {:0.4f}'.format(np.mean(train_loss_gender),train_acc_gender/890000,np.mean(train_loss_age),train_acc_age/890000))\n",
    "#                 train_loss_full.append(np.mean(train_loss)) # plot training loss\n",
    "        except KeyboardInterrupt:\n",
    "            t.close()\n",
    "            break\n",
    "        t.close()\n",
    "        \n",
    "        model.eval()\n",
    "        eval_loss_gender = []\n",
    "        eval_loss_age = []\n",
    "        eval_acc_gender = 0.\n",
    "        eval_acc_age = 0.\n",
    "        # evaluation every_10_epoches\n",
    "        with torch.no_grad():\n",
    "            for i in range(890000 // batch_size, 900000//batch_size):\n",
    "                \n",
    "                c_batch,a_batch, ad_batch, p_batch, in_batch, count_batch ,y_gender_batch,y_age_batch = \\\n",
    "                get_batch(i,batch_size, X_cid,X_aid, X_adid,X_pid,X_in, count_feature, y_gender_labels, y_age_labels)    \n",
    "                gender,age = model(c_batch.to(device),\n",
    "                                       a_batch.to(device), \n",
    "                                       ad_batch.to(device), \n",
    "                                       p_batch.to(device),\n",
    "                                       in_batch.to(device),\n",
    "                                       count_batch.to(device)\n",
    "                    )\n",
    "                loss1 = lossfunc1(gender,y_gender_batch.to(device))\n",
    "                loss2 = lossfunc2(age,y_age_batch.to(device))\n",
    "                \n",
    "                \n",
    "                eval_loss_gender.append(loss1.item())\n",
    "                eval_loss_age.append(loss2.item())\n",
    "                \n",
    "                pred_gender = torch.max(gender,1)[1]  # out_gender \n",
    "                eval_correct_gender = (pred_gender.cpu() == y_gender_batch).sum()\n",
    "                eval_acc_gender += eval_correct_gender.item() \n",
    "                \n",
    "                pred_age = torch.max(age,1)[1] # age_out\n",
    "                \n",
    "                eval_correct_age = ( pred_age.cpu() == y_age_batch).sum()\n",
    "                eval_acc_age += eval_correct_age.item()\n",
    "\n",
    "            print('Eval_loss_gender:{:0.4f},acc_gender = {:0.4f}, Eval_loss_age:{:0.4f},acc_age = {:0.4f}'.format(np.mean(eval_loss_gender),eval_acc_gender / 10000, np.mean(eval_loss_age),eval_acc_age / 10000))\n",
    "            print('score = {:0.4f}'.format(eval_acc_gender /10000  +  eval_acc_age / 10000))\n",
    "        scheduler.step(eval_acc_gender /10000 + eval_acc_age / 10000)\n",
    "        # save best model\n",
    "        if eval_acc_gender / 10000  +  eval_acc_age / 10000 > max_acc_sum:\n",
    "            print('-' * 20 + 'saving best model at epoch ' + str(epoch + 1))\n",
    "            max_acc_sum = eval_acc_gender / 10000 +  eval_acc_age / 10000\n",
    "            torch.save(model,save_path)\n",
    "\n",
    "            print('finished saving')\n",
    "    print('training finished')\n",
    "\n",
    "train_with_early_stopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = torch.load(save_path,map_location = lambda storage,loc:storage.cuda(0))\n",
    "print('loaded model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected Long (got Float)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-fd854a073692>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-fd854a073692>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mp_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfor_test_pid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0min_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfor_test_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mcount_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfor_test_count_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#             s_length = test_sequence_length[i * batch_size : (i+1) * batch_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mgender\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mad_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Long (got Float)"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    with torch.no_grad():\n",
    "        model.eval() \n",
    "        preds_gender = np.zeros(1000000)\n",
    "        preds_age = np.zeros(1000000)\n",
    "        print('begin predict')\n",
    "        for i in tqdm(range( 1000000 // batch_size)):\n",
    "\n",
    "            c_id = torch.LongTensor(for_test_cid[i * batch_size : (i+1) * batch_size])\n",
    "            a_id = torch.LongTensor(for_test_aid[i * batch_size : (i+1) * batch_size])\n",
    "            ad_id = torch.LongTensor(for_test_adid[i * batch_size : (i+1) * batch_size])\n",
    "            p_id = torch.LongTensor(for_test_pid[i * batch_size : (i+1) * batch_size])\n",
    "            in_id = torch.LongTensor(for_test_in[i * batch_size : (i+1) * batch_size])\n",
    "            count_batch = torch.FloatTensor(for_test_count_feature[i * batch_size : (i+1) * batch_size])\n",
    "#             s_length = test_sequence_length[i * batch_size : (i+1) * batch_size]\n",
    "            gender,age = model(c_id.cuda(0),a_id.cuda(0),ad_id.cuda(0),p_id.cuda(0),in_id.cuda(0),count_batch.cuda(0))\n",
    "            preds_gender[i * batch_size: (i+1) * batch_size] = torch.max(gender,1)[1].cpu().numpy() \n",
    "            preds_age[i * batch_size : (i+1) * batch_size] = torch.max(age,1)[1].cpu().numpy()\n",
    "        plt.figure(1)\n",
    "        sns.countplot(preds_gender)\n",
    "        plt.figure(2)\n",
    "        sns.countplot(preds_age)\n",
    "        # output = test_embedding_features[['user_id']]\n",
    "\n",
    "        output = pd.DataFrame(columns=['user_id'])\n",
    "        # print(len(test_preds_age))\n",
    "        output['user_id'] = list(range(3000001,4000001))\n",
    "        output['predicted_age'] = list(map(lambda x:int(x) + 1,preds_age))\n",
    "        output['predicted_gender']= list(map(lambda x:int(x) + 1,preds_gender))\n",
    "\n",
    "        import datetime\n",
    "        date_p = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "        output.to_csv('submit'+ date_p+ '.csv',index = False)\n",
    "\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_outputs(count_feature):\n",
    "#     torch.cuda.empty_cache()\n",
    "#     model.eval()\n",
    "    \n",
    "#     X_train_gender, X_train_age = None, None\n",
    "#     X_val_gender, X_val_age = None, None\n",
    "#     X_test_gender, X_test_age = None, None\n",
    "#     with torch.no_grad():\n",
    "#         for i in tqdm(range(720000 // batch_size)):\n",
    "            \n",
    "#             c_batch,a_batch, ad_batch, p_batch, in_batch, count_batch ,y_gender_batch,y_age_batch = \\\n",
    "#             get_batch(i,batch_size, X_cid,X_aid, X_adid,X_pid,X_in, count_feature, y_gender_labels, y_age_labels)\n",
    "#             gender,age = model(c_batch.cuda(1),a_batch.cuda(1),ad_batch.cuda(1),p_batch.cuda(1), in_batch.cuda(1), count_batch.cuda(1))\n",
    "\n",
    "#             gender_prob, age_prob = gender.cpu().detach().numpy() ,age.cpu().detach().numpy()\n",
    "\n",
    "#             if X_train_gender is None:\n",
    "#                 X_train_gender = gender_prob\n",
    "#                 X_train_age = age_prob\n",
    "#             else:\n",
    "#                 X_train_gender = np.vstack((X_train_gender, gender_prob))\n",
    "#                 X_train_age = np.vstack((X_train_age, age_prob))\n",
    "#         print(X_train_gender.shape,X_train_age.shape)\n",
    "\n",
    "#         for i in range(720000 // batch_size, 900000 // batch_size):\n",
    "#             c_batch,a_batch, ad_batch, p_batch, in_batch, count_batch ,y_gender_batch,y_age_batch = \\\n",
    "#             get_batch(i,batch_size, X_cid,X_aid, X_adid,X_pid,X_in, count_feature, y_gender_labels, y_age_labels)\n",
    "            \n",
    "#             gender,age = model(c_batch.cuda(1),a_batch.cuda(1),ad_batch.cuda(1),p_batch.cuda(1), in_batch.cuda(1), count_batch.cuda(1))\n",
    "\n",
    "\n",
    "#             gender_prob, age_prob = gender.cpu().detach().numpy(), age.cpu().detach().numpy()\n",
    "#             if X_val_gender is None:\n",
    "#                 X_val_gender = gender_prob\n",
    "#                 X_val_age = age_prob\n",
    "#             else:\n",
    "#                 X_val_gender = np.vstack((X_val_gender, gender_prob))\n",
    "#                 X_val_age = np.vstack((X_val_age, age_prob))\n",
    "#         print(X_val_gender.shape,X_val_age.shape)\n",
    "\n",
    "#         for i in tqdm(range(1000000 // batch_size)):\n",
    "\n",
    "\n",
    "#             c_id = torch.LongTensor(for_test_cid[i * batch_size : (i+1) * batch_size])\n",
    "#             a_id = torch.LongTensor(for_test_aid[i * batch_size : (i+1) * batch_size])\n",
    "#             ad_id = torch.LongTensor(for_test_adid[i * batch_size : (i+1) * batch_size])\n",
    "#             p_id = torch.LongTensor(for_test_pid[i * batch_size : (i+1) * batch_size])\n",
    "#             in_id = torch.LongTensor(for_test_in[i * batch_size : (i+1) * batch_size])\n",
    "#             count_feature = torch.FloatTensor(for_test_count_feature[i * batch_size : (i+1) * batch_size])\n",
    "# #             s_length = test_sequence_length[i * batch_size : (i+1) * batch_size]\n",
    "#             gender,age = model(c_id.cuda(1),a_id.cuda(1),ad_id.cuda(1),p_id.cuda(1),in_id.cuda(1),count_feature.cuda(1))\n",
    "#             gender_prob, age_prob = gender.cpu().detach().numpy(),age.cpu().detach().numpy()\n",
    "#             if X_test_gender is None:\n",
    "#                 X_test_gender = gender_prob\n",
    "#                 X_test_age = age_prob\n",
    "#             else:\n",
    "#                 X_test_gender = np.vstack((X_test_gender, gender_prob))\n",
    "#                 X_test_age = np.vstack((X_test_age, age_prob))\n",
    "#     print(X_test_gender.shape,X_test_age.shape)\n",
    "    \n",
    "#     return X_train_gender,X_train_age,X_val_gender,X_val_age,X_test_gender,X_test_age\n",
    "\n",
    "        \n",
    "# # X_train_gender,X_train_age,X_val_gender,X_val_age,X_test_gender,X_test_age = get_outputs(count_feature)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.hstack((X_train_gender,X_train_age))\n",
    "# X_val = np.hstack((X_val_gender,X_val_age))\n",
    "# X_test = np.hstack((X_test_gender,X_test_age))\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# lr_model1 = LogisticRegression(C = 1)\n",
    "# lr_model1.fit(train_set, y_gender_labels.numpy())\n",
    "# r2_score = lr_model1.score(train_set[720000:900000],y_gender_labels[720000:900000].numpy())\n",
    "# print(r2_score)\n",
    "# gender_preds = lr_model1.predict(test_set)\n",
    "# sns.countplot(gender_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_model2 = LogisticRegression(C = 1)\n",
    "# lr_model2.fit(train_set, y_age_labels.numpy())\n",
    "# r2_score = lr_model2.score(train_set[720000:900000],y_age_labels[720000:900000].numpy())\n",
    "# print(r2_score)\n",
    "# age_preds = lr_model2.predict(test_set)\n",
    "# sns.countplot(age_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = pd.DataFrame(columns=['user_id'])\n",
    "# # print(len(test_preds_age))\n",
    "# output['user_id'] = list(range(3000001,4000001))\n",
    "# output['predicted_age'] = list(map(lambda x:int(x) + 1,age_preds))\n",
    "# output['predicted_gender']= list(map(lambda x:int(x) + 1,gender_preds))\n",
    "\n",
    "# import datetime\n",
    "# date_p = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "# output.to_csv('submit'+ date_p+ '.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________TEST___________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # 输出性别\n",
    "\n",
    "# # test_x = scaler.transform(test_embedding_features.iloc[:,1:129])\n",
    "# # print(test_x)\n",
    "\n",
    "# test = test_user\n",
    "# # scaler2 = StandardScaler()\n",
    "# # scaler2.fit(test_1)\n",
    "# # test = scaler2.transform(test_1)\n",
    "# test_preds = lbt1.predict(test) # xgboost\n",
    "# test_preds =[round(v) + 1 for v in test_preds]\n",
    "# # print(test_preds)\n",
    "# sns.countplot(test_preds)\n",
    "# # test_acc = accuracy_score(y_test,test_preds)\n",
    "# # print('test_acc = ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 输出年龄\n",
    "# test_preds_age = lbt2.predict(test) # lightgbm\n",
    "# test_preds_age =[round(v) + 1 for v in test_preds_age]\n",
    "# # print(test_preds_age)\n",
    "# sns.countplot(test_preds_age)\n",
    "# # test_acc = accuracy_score(y_test,test_preds)\n",
    "# # print('test_acc = ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         self.c_conv = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = self.hidden_size * 2  + self.embed_dim1,\n",
    "#                       out_channels = self.out_channels,\n",
    "#                       kernel_size = self.kernel_size),\n",
    "#             nn.ReLU(inplace = True),\n",
    "#             nn.BatchNorm1d(self.out_channels),\n",
    "            \n",
    "# #             nn.Conv1d(in_channels = self.out_channels,\n",
    "# #                       out_channels = self.out_channels,\n",
    "# #                       kernel_size = self.kernel_size),\n",
    "# #             nn.ReLU(inplace = True),\n",
    "# #             nn.BatchNorm1d(self.out_channels),\n",
    "           \n",
    "#                                     ).to(device)\n",
    "        \n",
    "#         self.a_conv = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = self.hidden_size * 2 + self.embed_dim2,\n",
    "#                       out_channels = self.out_channels,\n",
    "#                       kernel_size = self.kernel_size),\n",
    "#             nn.ReLU(inplace = True),\n",
    "#             nn.BatchNorm1d(self.out_channels),\n",
    "            \n",
    "# #             nn.Conv1d(in_channels = self.out_channels,\n",
    "# #                       out_channels = self.out_channels,\n",
    "# #                       kernel_size = self.kernel_size),\n",
    "# #             nn.ReLU(inplace = True),\n",
    "# #             nn.BatchNorm1d(self.out_channels),\n",
    "            \n",
    "#                                 ).to(device)\n",
    "        \n",
    "#         self.ad_conv = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = self.hidden_size * 2+ self.embed_dim3,\n",
    "#                       out_channels = self.out_channels,\n",
    "#                       kernel_size = self.kernel_size),\n",
    "#             nn.ReLU(inplace = True),\n",
    "#             nn.BatchNorm1d(self.out_channels),\n",
    "            \n",
    "                            \n",
    "# #             nn.Conv1d(in_channels = self.out_channels,\n",
    "# #                       out_channels = self.out_channels,\n",
    "# #                       kernel_size = self.kernel_size),\n",
    "# #             nn.ReLU(inplace = True),\n",
    "# #             nn.BatchNorm1d(self.out_channels),\n",
    "            \n",
    "#                             ).to(device)\n",
    "        \n",
    "        \n",
    "#         self.pc_conv = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = self.hidden_size * 2 + self.embed_dim4,\n",
    "#                       out_channels = self.out_channels,\n",
    "#                       kernel_size = self.kernel_size),\n",
    "#             nn.ReLU(inplace = True),\n",
    "#             nn.BatchNorm1d(self.out_channels),\n",
    "            \n",
    "                            \n",
    "# #             nn.Conv1d(in_channels = self.out_channels,\n",
    "# #                       out_channels = self.out_channels,\n",
    "# #                       kernel_size = self.kernel_size),\n",
    "# #             nn.ReLU(inplace = True),\n",
    "# #             nn.BatchNorm1d(self.out_channels),\n",
    "            \n",
    "#                             ).to(device)\n",
    "        \n",
    "#         self.in_conv = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = self.hidden_size * 2 + self.embed_dim5,\n",
    "#                       out_channels = self.out_channels,\n",
    "#                       kernel_size = self.kernel_size),\n",
    "#             nn.ReLU(inplace = True),\n",
    "#             nn.BatchNorm1d(self.out_channels),\n",
    "            \n",
    "                            \n",
    "# #             nn.Conv1d(in_channels = self.out_channels,\n",
    "# #                       out_channels = self.out_channels,\n",
    "# #                       kernel_size = self.kernel_size),\n",
    "# #             nn.ReLU(inplace = True),\n",
    "# #             nn.BatchNorm1d(self.out_channels),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_num =10\n",
    "# def search_weight(valid_y, raw_prob, init_weight=[1.0]*class_num, step=0.001):\n",
    "#     weight = init_weight.copy()\n",
    "#     f_best = accuracy_score(y_true=valid_y, y_pred=raw_prob.argmax(axis=1))\n",
    "#     flag_score = 0\n",
    "#     round_num = 1\n",
    "#     while(flag_score != f_best):\n",
    "#         print(\"round: \", round_num)\n",
    "#         round_num += 1\n",
    "#         flag_score = f_best\n",
    "#         for c in range(class_num):\n",
    "#             for n_w in range(0, 2000,10):\n",
    "#                 num = n_w * step\n",
    "#                 new_weight = weight.copy()\n",
    "#                 new_weight[c] = num\n",
    "#                 prob_df = raw_prob.copy()\n",
    "\n",
    "#                 prob_df = prob_df * np.array(new_weight)\n",
    "#                 f = accuracy_score(y_true=valid_y, y_pred=prob_df.argmax(\n",
    "\n",
    "#                     axis=1))\n",
    "#                 if f > f_best:\n",
    "#                     weight = new_weight.copy()\n",
    "#                     f_best = f\n",
    "#                     print(f)\n",
    "#     return weight\n",
    "#     class_num = 10\n",
    "    \n",
    "#     w = np.zeros((10000 // batch_size, class_num))\n",
    "\n",
    "#     # search weight\n",
    "#     for i in range(890000 // batch_size, 900000//batch_size):\n",
    "        \n",
    "#         c_batch,a_batch,ad_batch, ct_mask , y_gender_batch,y_age_batch = get_batch(i,batch_size)\n",
    "# #                 c_tf_batch, a_tf_batch ,ad_tf_batch, pc_tf_batch, in_tf_batch = get_tfidf_features(i,batch_size)\n",
    "#         ct_mask = ct_mask.unsqueeze(2).repeat(1,1, 2 * hidden_size)\n",
    "# #                 ct_mask = (ct_mask / torch.sum(ct_mask,dim=1).unsqueeze(1)).unsqueeze(2).repeat(1,1,2 * hidden_size)\n",
    "#         gender,age = model(c_batch.cuda(2),\n",
    "#                            a_batch.cuda(2), \n",
    "#                            ad_batch.cuda(2), \n",
    "# #                            pc_batch.cuda(1),\n",
    "# #                            in_batch.cuda(1), \n",
    "#                            ct_mask.cuda(2))\n",
    "#         del c_batch, a_batch, ad_batch\n",
    "#         weight = search_weight(y_age_batch.detach().numpy(), F.softmax(age,dim=1).cpu().detach().numpy())\n",
    "#         w[i - 890000 // batch_size] = weight\n",
    "    \n",
    "    \n",
    "#     weights = np.mean(w, axis = 0) # numpy\n",
    "#     print(weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
